{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1X68P3wSWGfP0HJpZ0EDy0s9fuvFWKGXv",
      "authorship_tag": "ABX9TyMS3QQd1uLeQl8RsD1aNelE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moon-123/NLP-Okt/blob/main/%08%ED%95%9C%EA%B5%AD%EC%96%B4_NLP_%EA%B3%BC%EC%A0%9C(Okt%2C_%EB%AA%85%EC%82%AC%2B%EB%8F%99%EC%82%AC%EC%9B%90%ED%98%95).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 문화, 게임 콘텐츠 분야 용어 말뭉치"
      ],
      "metadata": {
        "id": "sLdODNN33ejD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 데이터 불러오기"
      ],
      "metadata": {
        "id": "usnXZ-G43vu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('/content/drive/MyDrive/KDT/자연어 처리/data/용례_레저.json', 'r') as file:\n",
        "    json_data = json.load(file)\n"
      ],
      "metadata": {
        "id": "UGQyHC2Z3xWZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQhpZL6U9fb2",
        "outputId": "ae19f270-579a-4712-d287-e5824983e5ab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 3087876,\n",
              " 'sentence': '김치볶음 해놓은거에 밥비벼먹고 카레 해먹고',\n",
              " 'tokens': [{'start': 0,\n",
              "   'length': 4,\n",
              "   'sub': '김치볶음',\n",
              "   'facet': '구체물',\n",
              "   'term_id': 134217,\n",
              "   'sense_no': 1}],\n",
              " 'sense_no': 1,\n",
              " 'source': {'uri': 'https://bbs.ruliweb.com/community/board/300143/read/58933395',\n",
              "  'text': '일주일동안 탄수화물 위주로만 먹었어\\r\\n\\r\\n\\r\\n김치볶음 해놓은거에 밥비벼먹고 카레 해먹고\\r\\n\\r\\n\\r\\n점심에는 김밥에 쫄면에 돈까스 먹었는데\\r\\n\\r\\n\\r\\n그래도 단백질이 먹고싶다',\n",
              "  'written_at': '2022-10-15T08:04:00'}}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-1. 'sentence'\n",
        "* 'sentence'는 source text에서 추출된 문장."
      ],
      "metadata": {
        "id": "NduOlP4t99YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# source의 text를 정제/추출해도 되는데 과제는 전처리가 아니라 임베딩이므로 생략\n",
        "# sentence를 사용\n",
        "sentence_list = [data['sentence'] for data in json_data]\n",
        "print(sentence_list[:5])\n",
        "print(len(sentence_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxvGtmjK8Qbo",
        "outputId": "19398d5a-4549-4d5a-cc8e-e67d62691a13"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['김치볶음 해놓은거에 밥비벼먹고 카레 해먹고', '전과하고 싶어지네 전적대에서 다니던 과로 전과할까 해도 이번학기 학점이 1~2점 나올거 같아서 재편입 해야하나 싶다...', '중요한건 저기 예시로 든건 노트북용도 아닌 컴터용 시퓨다', '의자를 좀 더 편한걸로 바꿔주면 딱이네 빈백 같은거', '수석이니하면서 장미빛 미래를 꿈꾸고 있을']\n",
            "75384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-2. 한국어 토크나이저 Okt사용\n"
      ],
      "metadata": {
        "id": "Ip0g0iZ1B2Jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install KoNLPy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRoA0KaDBUBc",
        "outputId": "0554e08f-f35d-4411-f7cc-3f14257ff5bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting KoNLPy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from KoNLPy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from KoNLPy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from KoNLPy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->KoNLPy) (23.2)\n",
            "Installing collected packages: JPype1, KoNLPy\n",
            "Successfully installed JPype1-1.5.0 KoNLPy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()"
      ],
      "metadata": {
        "id": "Ealsoo9xBQDh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenized_sentence = okt.pos(sentence_list[0], norm=True, stem=True)\n",
        "# tokenized_sentence[0][1] == 'Noun'\n",
        "\n",
        "def extract_nouns_and_verbs(text):\n",
        "    pos_sentence = []\n",
        "    pos_tags = okt.pos(text, norm=True, stem=True)\n",
        "\n",
        "    pos_sentence = [word for word, pos in pos_tags if (pos == 'Noun') or (pos == 'Verb')]\n",
        "\n",
        "\n",
        "    return pos_sentence"
      ],
      "metadata": {
        "id": "J_e3jnYnPvdS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentence_list = []\n",
        "\n",
        "for sentence in sentence_list:\n",
        "    tokenized_sentence_list.append(extract_nouns_and_verbs(sentence))\n",
        "\n",
        "# tokenized_sentence_list\n",
        "# 명사, 동사원형을 제외하고 삭제"
      ],
      "metadata": {
        "id": "Fz02wmXrFL95"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-2. 불용어, 특수문자 제거\n",
        "* okt에서 명사만 뽑았기 때문에 특수문자 제거는 생략"
      ],
      "metadata": {
        "id": "MOeIiQyJ_ZGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_list = set(open('/content/drive/MyDrive/KDT/자연어 처리/data/stopword.txt').read().split('\\n')).union(['거', '점', '걸', '더', '게', '것', '데', '참', '뭘', '쭉'])\n",
        "len(stopwords_list)\n",
        "pre_sentence_list = []\n",
        "for sentence in tokenized_sentence_list:\n",
        "    word_list = []\n",
        "    for word in sentence:\n",
        "        if word not in stopwords_list:\n",
        "            word_list.append(word)\n",
        "\n",
        "    pre_sentence_list.append(word_list)\n",
        "\n",
        "len(pre_sentence_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB65FKL6AYsq",
        "outputId": "df2e95a8-7734-4543-cc64-279d1d2e68a2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75384"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 제거 후 확인\n",
        "print(pre_sentence_list[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOvLgYCFPND4",
        "outputId": "6ae3e1c5-67c4-45d5-e298-c94c31596331"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['김치', '볶음', '밥', '비비다', '먹다', '카레', '해먹'], ['전과', '싶다', '전적', '다니다', '과로', '전과', '해도', '학기', '학점', '나오다', '재', '편입', '싶다'], ['예시', '들다', '노트북', '용도', '컴터', '용', '시퓨'], ['의자', '바꾸다', '빈'], ['수석', '장미', '빛', '미래', '꿈꾸다']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 빈 리스트 제거\n",
        "sentence_list = []\n",
        "for ps in pre_sentence_list:\n",
        "    if len(ps) != 0:\n",
        "        sentence_list.append(ps)\n",
        "\n",
        "print(len(sentence_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkezypTIY7ZZ",
        "outputId": "40650442-8d03-44fc-b8d1-c03a0dab06ea"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_list[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msGIvzzJaP4t",
        "outputId": "18bc33fe-59db-48a5-cd12-a3ea9a2d909b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['김치', '볶음', '밥', '비비다', '먹다', '카레', '해먹'], ['전과', '싶다', '전적', '다니다', '과로', '전과', '해도', '학기', '학점', '나오다', '재', '편입', '싶다'], ['예시', '들다', '노트북', '용도', '컴터', '용', '시퓨'], ['의자', '바꾸다', '빈'], ['수석', '장미', '빛', '미래', '꿈꾸다']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-3. Tokenizer로 단어에 라벨링"
      ],
      "metadata": {
        "id": "292mn1GZVKiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pre_sentence_list를 가지고 라벨링\n",
        "# 지금 리스트니까 str 문장으로 변환해야할까?\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "SCL6FFQbQXXK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentence_list)"
      ],
      "metadata": {
        "id": "2_ZgmkafS8xH"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = tokenizer.word_index\n",
        "# print(word2idx)\n",
        "print(len(word2idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lh8GyuEmSigJ",
        "outputId": "9ea7b5c3-93e7-4545-9901-ec46579eaa74"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx2word = {value : key for key, value in word2idx.items()}\n",
        "\n",
        "vocab_size = len(idx2word)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBpuEg9YUbi6",
        "outputId": "bdef284e-d0c0-4e3d-e969-77833ac9690f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = tokenizer.texts_to_sequences(sentence_list)\n",
        "print(encoded[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTW_RSRjUxdO",
        "outputId": "37c3225a-3291-41a3-a095-6f4958c41ed0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[76, 187, 37, 1005, 1, 613, 817], [4353, 24, 4690, 94, 11342, 4353, 172, 3770, 8710, 3, 60, 3099, 24]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7sHcqRWV9fg",
        "outputId": "975f8ac4-7b61-42d8-9cb8-0ec933c7b464"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75381"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-4. skipgrams로 임베딩 준비"
      ],
      "metadata": {
        "id": "qnSygYgSU8T5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import skipgrams"
      ],
      "metadata": {
        "id": "2SnOJa9VVWsC"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoded에서 랜덤하게 리스트를 슬라이싱하기\n",
        "import random\n",
        "random_encoded_100 = random.sample(encoded, 100)\n"
      ],
      "metadata": {
        "id": "qTrIpm2fVw5V"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# edcoded 총 개수가 33997.\n",
        "skip_grams = [skipgrams(sample, vocabulary_size=vocab_size, window_size=5) for sample in random_encoded_100]\n",
        "print(f'{len(skip_grams)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJFxfJcybNFX",
        "outputId": "099022da-bff1-4774-ab78-8c8d04f67e0f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sg in enumerate(skip_grams):\n",
        "    if len(sg[0]) <= 2:\n",
        "        print(f'{i}: {sg}')\n",
        "\n",
        "# 빈 값이 있는 것 같아서 확인함\n",
        "# 명사만 추출한 경우엔 윈도우 사이즈가 적당해야했지만 명사와 동사원형을 추출하다보니 윈도우 사이즈에 제약이 줄었음."
      ],
      "metadata": {
        "id": "KrlsHZXAXAKq"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-5. 학습을 위한 모델 만들기"
      ],
      "metadata": {
        "id": "eS5HyFMIWgEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, Reshape, Activation, Input, Dot\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "EvdtLghIVtYw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "w_inputs = Input(shape=(1,), dtype='int32')\n",
        "word_embedding = Embedding(vocab_size, embedding_dim)(w_inputs)\n",
        "\n",
        "c_inputs = Input(shape=(1,), dtype='int32')\n",
        "context_embedding = Embedding(vocab_size, embedding_dim)(c_inputs)\n"
      ],
      "metadata": {
        "id": "q9pEx0bbWIFG"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dot_product = Dot(axes=2)([word_embedding, context_embedding])\n",
        "dot_product = Reshape((1,), input_shape=(1, 1))(dot_product)\n",
        "output = Activation('sigmoid')(dot_product)\n",
        "\n",
        "model = Model(inputs=[w_inputs, c_inputs], outputs=output)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wTEwwFEWNpR",
        "outputId": "18cb72fe-9890-4333-da0b-1a3bb9ec11e6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 1, 100)               3517300   ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 1, 100)               3517300   ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " dot (Dot)                   (None, 1, 1)                 0         ['embedding[0][0]',           \n",
            "                                                                     'embedding_1[0][0]']         \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 1)                    0         ['dot[0][0]']                 \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 1)                    0         ['reshape[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 7034600 (26.83 MB)\n",
            "Trainable params: 7034600 (26.83 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "WkoAV3ggWTjO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-6. 학습"
      ],
      "metadata": {
        "id": "Zq-jl9TmWWAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "sSIuaZgNWn8M"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "    loss = 0\n",
        "    for _, elem in enumerate(skip_grams):\n",
        "        if elem[0]:\n",
        "            first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
        "            second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
        "            labels = np.array(elem[1], dtype='int32')\n",
        "            X = [first_elem, second_elem]\n",
        "            Y = labels\n",
        "            loss += model.train_on_batch(X, Y)\n",
        "    print('Epoch: ', epoch+1, 'Loss: ', loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25WlTjvDWbkI",
        "outputId": "b7e8d4f9-6c6a-4339-f54d-29dbd0463fd6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1 Loss:  69.31307345628738\n",
            "Epoch:  2 Loss:  68.40207976102829\n",
            "Epoch:  3 Loss:  66.90074932575226\n",
            "Epoch:  4 Loss:  64.30526381731033\n",
            "Epoch:  5 Loss:  60.352422058582306\n",
            "Epoch:  6 Loss:  55.126506835222244\n",
            "Epoch:  7 Loss:  48.99506130814552\n",
            "Epoch:  8 Loss:  42.45842531323433\n",
            "Epoch:  9 Loss:  36.00636710226536\n",
            "Epoch:  10 Loss:  30.025200575590134\n",
            "Epoch:  11 Loss:  24.75468309223652\n",
            "Epoch:  12 Loss:  20.28902331739664\n",
            "Epoch:  13 Loss:  16.610417380928993\n",
            "Epoch:  14 Loss:  13.634554840624332\n",
            "Epoch:  15 Loss:  11.25035334378481\n",
            "Epoch:  16 Loss:  9.346167247742414\n",
            "Epoch:  17 Loss:  7.82304173707962\n",
            "Epoch:  18 Loss:  6.599111013114452\n",
            "Epoch:  19 Loss:  5.6092375963926315\n",
            "Epoch:  20 Loss:  4.802680717781186\n",
            "Epoch:  21 Loss:  4.140311267226934\n",
            "Epoch:  22 Loss:  3.5920459926128387\n",
            "Epoch:  23 Loss:  3.1347236577421427\n",
            "Epoch:  24 Loss:  2.7504370771348476\n",
            "Epoch:  25 Loss:  2.425260222516954\n",
            "Epoch:  26 Loss:  2.148289058357477\n",
            "Epoch:  27 Loss:  1.9109234623610973\n",
            "Epoch:  28 Loss:  1.706329989247024\n",
            "Epoch:  29 Loss:  1.529038685373962\n",
            "Epoch:  30 Loss:  1.3746392140164971\n",
            "Epoch:  31 Loss:  1.2395506803877652\n",
            "Epoch:  32 Loss:  1.1208460084162652\n",
            "Epoch:  33 Loss:  1.0161171625368297\n",
            "Epoch:  34 Loss:  0.9233708479441702\n",
            "Epoch:  35 Loss:  0.8409474650397897\n",
            "Epoch:  36 Loss:  0.7674575760029256\n",
            "Epoch:  37 Loss:  0.7017317325808108\n",
            "Epoch:  38 Loss:  0.6427807433065027\n",
            "Epoch:  39 Loss:  0.5897638909518719\n",
            "Epoch:  40 Loss:  0.5419634282588959\n",
            "Epoch:  41 Loss:  0.49876392306759953\n",
            "Epoch:  42 Loss:  0.4596355555113405\n",
            "Epoch:  43 Loss:  0.42412042897194624\n",
            "Epoch:  44 Loss:  0.3918213143479079\n",
            "Epoch:  45 Loss:  0.362392439506948\n",
            "Epoch:  46 Loss:  0.3355317700188607\n",
            "Epoch:  47 Loss:  0.31097470049280673\n",
            "Epoch:  48 Loss:  0.2884886347455904\n",
            "Epoch:  49 Loss:  0.2678685642313212\n",
            "Epoch:  50 Loss:  0.2489332800032571\n",
            "Epoch:  51 Loss:  0.23152219236362725\n",
            "Epoch:  52 Loss:  0.2154926098883152\n",
            "Epoch:  53 Loss:  0.20071745535824448\n",
            "Epoch:  54 Loss:  0.18708326667547226\n",
            "Epoch:  55 Loss:  0.17448855587281287\n",
            "Epoch:  56 Loss:  0.1628423203364946\n",
            "Epoch:  57 Loss:  0.1520627848803997\n",
            "Epoch:  58 Loss:  0.1420763596543111\n",
            "Epoch:  59 Loss:  0.13281666819239035\n",
            "Epoch:  60 Loss:  0.12422373617300764\n",
            "Epoch:  61 Loss:  0.11624329799087718\n",
            "Epoch:  62 Loss:  0.10882614558795467\n",
            "Epoch:  63 Loss:  0.1019276095321402\n",
            "Epoch:  64 Loss:  0.09550706628942862\n",
            "Epoch:  65 Loss:  0.08952752553159371\n",
            "Epoch:  66 Loss:  0.08395525178639218\n",
            "Epoch:  67 Loss:  0.07875944211264141\n",
            "Epoch:  68 Loss:  0.07391193011426367\n",
            "Epoch:  69 Loss:  0.06938692793482915\n",
            "Epoch:  70 Loss:  0.06516079933498986\n",
            "Epoch:  71 Loss:  0.06121185849769972\n",
            "Epoch:  72 Loss:  0.05752018536441028\n",
            "Epoch:  73 Loss:  0.05406745680375025\n",
            "Epoch:  74 Loss:  0.05083681031828746\n",
            "Epoch:  75 Loss:  0.04781270574312657\n",
            "Epoch:  76 Loss:  0.04498080856865272\n",
            "Epoch:  77 Loss:  0.04232788848457858\n",
            "Epoch:  78 Loss:  0.03984172201307956\n",
            "Epoch:  79 Loss:  0.037511008165893145\n",
            "Epoch:  80 Loss:  0.03532528232608456\n",
            "Epoch:  81 Loss:  0.03327485978661571\n",
            "Epoch:  82 Loss:  0.03135075820318889\n",
            "Epoch:  83 Loss:  0.02954465092625469\n",
            "Epoch:  84 Loss:  0.027848808880662546\n",
            "Epoch:  85 Loss:  0.026256050376105122\n",
            "Epoch:  86 Loss:  0.024759705818723887\n",
            "Epoch:  87 Loss:  0.02335356736148242\n",
            "Epoch:  88 Loss:  0.022031866101315245\n",
            "Epoch:  89 Loss:  0.020789224116015248\n",
            "Epoch:  90 Loss:  0.019620637540356256\n",
            "Epoch:  91 Loss:  0.018521438985771965\n",
            "Epoch:  92 Loss:  0.017487278128101025\n",
            "Epoch:  93 Loss:  0.01651409696933115\n",
            "Epoch:  94 Loss:  0.015598106634570286\n",
            "Epoch:  95 Loss:  0.014735771983396262\n",
            "Epoch:  96 Loss:  0.013923785598308314\n",
            "Epoch:  97 Loss:  0.013159058784367517\n",
            "Epoch:  98 Loss:  0.012438706900866237\n",
            "Epoch:  99 Loss:  0.011760030596633442\n",
            "Epoch:  100 Loss:  0.011120502873382065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n"
      ],
      "metadata": {
        "id": "bGREoKHrWuNY"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('vectors.txt', 'w')\n",
        "f.write('{} {}\\n'.format(vocab_size, embedding_dim))\n",
        "vectors = model.get_weights()[0]\n",
        "\n",
        "print(vectors)\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    f.write('{} {}\\n'.format(word, ' '.join(map(str, list(vectors[i-1, :])))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEYmhfekhTz2",
        "outputId": "8f7a2add-8834-4518-f107-848c72d53b73"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.02698928  0.00931174  0.03408981 ...  0.02772317 -0.03054793\n",
            "   0.00105447]\n",
            " [-0.59130096 -0.8258808  -0.6383123  ...  0.70729196  0.17827253\n",
            "  -0.6512729 ]\n",
            " [ 0.30506632 -0.61675763 -0.5821475  ...  0.5824413  -0.5917793\n",
            "  -0.7724286 ]\n",
            " ...\n",
            " [-0.01168431  0.01931765 -0.00242277 ... -0.04077073  0.02409116\n",
            "   0.01764495]\n",
            " [-0.02997527  0.00955244  0.01048    ... -0.04364777 -0.01908641\n",
            "   0.04691038]\n",
            " [-0.03582549  0.02726832 -0.01737507 ...  0.02078445 -0.04168485\n",
            "  -0.02958456]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v = gensim.models.KeyedVectors.load_word2vec_format('./vectors.txt', binary=False)"
      ],
      "metadata": {
        "id": "rZi3XAhMhMa6"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v.most_similar(positive=['악어'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGmgQKkHhQvG",
        "outputId": "fdf50a03-21a6-4917-aefd-faf9f7ff28e9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('뽀록나다', 0.43311867117881775),\n",
              " ('오피스', 0.3811410665512085),\n",
              " ('순두부찌개', 0.3756980895996094),\n",
              " ('비사', 0.37259188294410706),\n",
              " ('플래시', 0.36377960443496704),\n",
              " ('미텐스', 0.36125078797340393),\n",
              " ('은줄', 0.360832154750824),\n",
              " ('롤드컵', 0.3543761968612671),\n",
              " ('작문', 0.35200151801109314),\n",
              " ('등장인물', 0.3454458713531494)]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v.most_similar(positive=['눈물'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb57efcGiFc0",
        "outputId": "24fab40c-1f5c-4406-a6ce-e392052c570a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('글카', 0.41196003556251526),\n",
              " ('별하늘', 0.38758835196495056),\n",
              " ('방물', 0.3807717561721802),\n",
              " ('예감', 0.37183961272239685),\n",
              " ('어솨', 0.3666045665740967),\n",
              " ('직촬보', 0.36536285281181335),\n",
              " ('생지옥', 0.3575366735458374),\n",
              " ('신앙심', 0.3501545786857605),\n",
              " ('눈시울', 0.34760603308677673),\n",
              " ('직빵임', 0.34690073132514954)]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5DXhamt7iKIB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
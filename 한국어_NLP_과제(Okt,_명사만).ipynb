{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1TN_hHb0Q-BhyVQ2L8GI0B0PRnz-XQW76",
      "authorship_tag": "ABX9TyMbBwdeg7DY5eF41m1TT5mg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moon-123/NLP-Okt/blob/main/%08%ED%95%9C%EA%B5%AD%EC%96%B4_NLP_%EA%B3%BC%EC%A0%9C(Okt%2C_%EB%AA%85%EC%82%AC%EB%A7%8C).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 문화, 게임 콘텐츠 분야 용어 말뭉치"
      ],
      "metadata": {
        "id": "sLdODNN33ejD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 데이터 불러오기"
      ],
      "metadata": {
        "id": "usnXZ-G43vu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('/content/drive/MyDrive/KDT/자연어 처리/data/용례_레저.json', 'r') as file:\n",
        "    json_data = json.load(file)\n"
      ],
      "metadata": {
        "id": "UGQyHC2Z3xWZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQhpZL6U9fb2",
        "outputId": "045f6339-beda-45d4-cf7c-d5f28afc39a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 3087876,\n",
              " 'sentence': '김치볶음 해놓은거에 밥비벼먹고 카레 해먹고',\n",
              " 'tokens': [{'start': 0,\n",
              "   'length': 4,\n",
              "   'sub': '김치볶음',\n",
              "   'facet': '구체물',\n",
              "   'term_id': 134217,\n",
              "   'sense_no': 1}],\n",
              " 'sense_no': 1,\n",
              " 'source': {'uri': 'https://bbs.ruliweb.com/community/board/300143/read/58933395',\n",
              "  'text': '일주일동안 탄수화물 위주로만 먹었어\\r\\n\\r\\n\\r\\n김치볶음 해놓은거에 밥비벼먹고 카레 해먹고\\r\\n\\r\\n\\r\\n점심에는 김밥에 쫄면에 돈까스 먹었는데\\r\\n\\r\\n\\r\\n그래도 단백질이 먹고싶다',\n",
              "  'written_at': '2022-10-15T08:04:00'}}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-1. 'sentence'\n",
        "* 'sentence'는 source text에서 추출된 문장."
      ],
      "metadata": {
        "id": "NduOlP4t99YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# source의 text를 정제/추출해도 되는데 과제는 전처리가 아니라 임베딩이므로 생략\n",
        "# sentence를 사용\n",
        "sentence_list = [data['sentence'] for data in json_data]\n",
        "print(sentence_list[:5])\n",
        "print(len(sentence_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxvGtmjK8Qbo",
        "outputId": "3c703537-76a7-4bb1-c8b6-cdbfef1f23f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['김치볶음 해놓은거에 밥비벼먹고 카레 해먹고', '전과하고 싶어지네 전적대에서 다니던 과로 전과할까 해도 이번학기 학점이 1~2점 나올거 같아서 재편입 해야하나 싶다...', '중요한건 저기 예시로 든건 노트북용도 아닌 컴터용 시퓨다', '의자를 좀 더 편한걸로 바꿔주면 딱이네 빈백 같은거', '수석이니하면서 장미빛 미래를 꿈꾸고 있을']\n",
            "75384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-2. 한국어 토크나이저 Okt사용\n"
      ],
      "metadata": {
        "id": "Ip0g0iZ1B2Jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install KoNLPy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRoA0KaDBUBc",
        "outputId": "11d18045-ad71-4f0f-8ab8-a46e28acc583"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting KoNLPy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from KoNLPy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from KoNLPy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from KoNLPy) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->KoNLPy) (23.2)\n",
            "Installing collected packages: JPype1, KoNLPy\n",
            "Successfully installed JPype1-1.5.0 KoNLPy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()"
      ],
      "metadata": {
        "id": "Ealsoo9xBQDh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentence_list = []\n",
        "\n",
        "for sentence in sentence_list:\n",
        "    tokenized_sentence = okt.nouns(sentence)\n",
        "    tokenized_sentence_list.append(tokenized_sentence)\n",
        "# tokenized_sentence_list"
      ],
      "metadata": {
        "id": "Fz02wmXrFL95"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenized_sentence_list)\n",
        "\n",
        "print(tokenized_sentence_list[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G66FiuXGN5Sz",
        "outputId": "d551d966-2135-40dd-e18c-c8716023efb7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['김치', '볶음', '거', '밥', '카레', '해먹']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-2. 불용어, 특수문자 제거\n",
        "* okt에서 명사만 뽑았기 때문에 특수문자 제거는 생략"
      ],
      "metadata": {
        "id": "MOeIiQyJ_ZGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "added_sw = ['거', '점', '걸', '더', '게', '것', '데', '참', '뭘', '쭉']\n",
        "stopwords_list = set(open('/content/drive/MyDrive/KDT/자연어 처리/data/stopword.txt').read().split('\\n')).union(added_sw)\n",
        "len(stopwords_list)\n",
        "pre_sentence_list = []\n",
        "for sentence in tokenized_sentence_list:\n",
        "    word_list = []\n",
        "    for word in sentence:\n",
        "        if word not in stopwords_list:\n",
        "            word_list.append(word)\n",
        "\n",
        "    pre_sentence_list.append(word_list)\n",
        "\n",
        "len(pre_sentence_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB65FKL6AYsq",
        "outputId": "cdfca2b1-8778-4f3a-8daf-85d2c3d53fa0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75384"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 제거 후 확인\n",
        "print(pre_sentence_list[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOvLgYCFPND4",
        "outputId": "da91883d-d676-4380-c989-0a5b618f90fe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['김치', '볶음', '밥', '카레', '해먹'], ['전과', '전적', '과로', '전과', '해도', '학기', '학점', '재', '편입'], ['예시', '노트북', '용도', '컴터', '용', '시퓨'], ['의자', '빈'], ['수석', '장미', '빛', '미래']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_list = []\n",
        "for ps in pre_sentence_list:\n",
        "    if len(ps) != 0:\n",
        "        sentence_list.append(ps)\n",
        "\n",
        "print(len(sentence_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkezypTIY7ZZ",
        "outputId": "0d316287-92d4-4150-9425-9d7e3b6e97b8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence_list[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msGIvzzJaP4t",
        "outputId": "ed130bf4-a659-4f92-f4f0-4dfa4b786e5e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['김치', '볶음', '밥', '카레', '해먹'], ['전과', '전적', '과로', '전과', '해도', '학기', '학점', '재', '편입'], ['예시', '노트북', '용도', '컴터', '용', '시퓨'], ['의자', '빈'], ['수석', '장미', '빛', '미래']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-3. Tokenizer로 단어에 라벨링"
      ],
      "metadata": {
        "id": "292mn1GZVKiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pre_sentence_list를 가지고 라벨링\n",
        "# 지금 리스트니까 str 문장으로 변환해야할까?\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "SCL6FFQbQXXK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentence_list)"
      ],
      "metadata": {
        "id": "2_ZgmkafS8xH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = tokenizer.word_index\n",
        "# print(word2idx)\n",
        "print(len(word2idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lh8GyuEmSigJ",
        "outputId": "abe16492-6022-4002-f604-eb76977562e6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx2word = {value : key for key, value in word2idx.items()}\n",
        "\n",
        "vocab_size = len(idx2word)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBpuEg9YUbi6",
        "outputId": "af3edca4-234e-4624-f54b-fce924072bef"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = tokenizer.texts_to_sequences(sentence_list)\n",
        "print(encoded[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTW_RSRjUxdO",
        "outputId": "17c9206b-d87a-410c-c60c-9bffea71830d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[48, 129, 19, 484, 659], [3845, 4161, 10550, 3845, 120, 3305, 8000, 35, 2675]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7sHcqRWV9fg",
        "outputId": "d76a4f4b-6df5-4e7b-93af-53b57d4dbfee"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75363"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-4. skipgrams로 임베딩 준비"
      ],
      "metadata": {
        "id": "qnSygYgSU8T5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import skipgrams"
      ],
      "metadata": {
        "id": "2SnOJa9VVWsC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# edcoded 총 개수가 33997.\n",
        "skip_grams = [skipgrams(sample, vocabulary_size=vocab_size, window_size=5) for sample in encoded[:500]]\n",
        "print(f'{len(skip_grams)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJFxfJcybNFX",
        "outputId": "59c9a6cf-5a33-4637-ca33-101bd19d43e2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, sg in enumerate(skip_grams):\n",
        "    if len(sg[0]) <= 2:\n",
        "        print(f'{i}: {sg}')\n",
        "\n",
        "# 빈 값이 있는 것 같아서 확인함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrlsHZXAXAKq",
        "outputId": "5b451144-2f43-4e21-b278-96d7733a867e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "223: ([], [])\n",
            "428: ([], [])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-5. 학습을 위한 모델 만들기"
      ],
      "metadata": {
        "id": "eS5HyFMIWgEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, Reshape, Activation, Input, Dot\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "EvdtLghIVtYw"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "w_inputs = Input(shape=(1,), dtype='int32')\n",
        "word_embedding = Embedding(vocab_size, embedding_dim)(w_inputs)\n",
        "\n",
        "c_inputs = Input(shape=(1,), dtype='int32')\n",
        "context_embedding = Embedding(vocab_size, embedding_dim)(c_inputs)\n"
      ],
      "metadata": {
        "id": "q9pEx0bbWIFG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dot_product = Dot(axes=2)([word_embedding, context_embedding])\n",
        "dot_product = Reshape((1,), input_shape=(1, 1))(dot_product)\n",
        "output = Activation('sigmoid')(dot_product)\n",
        "\n",
        "model = Model(inputs=[w_inputs, c_inputs], outputs=output)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wTEwwFEWNpR",
        "outputId": "dbd3f9ec-8770-4f5b-f2e5-bdc454d89243"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, 1, 100)               3398900   ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, 1, 100)               3398900   ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " dot (Dot)                   (None, 1, 1)                 0         ['embedding[0][0]',           \n",
            "                                                                     'embedding_1[0][0]']         \n",
            "                                                                                                  \n",
            " reshape (Reshape)           (None, 1)                    0         ['dot[0][0]']                 \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 1)                    0         ['reshape[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6797800 (25.93 MB)\n",
            "Trainable params: 6797800 (25.93 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "WkoAV3ggWTjO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-6. 학습"
      ],
      "metadata": {
        "id": "Zq-jl9TmWWAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "sSIuaZgNWn8M"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "    loss = 0\n",
        "    for _, elem in enumerate(skip_grams):\n",
        "        if elem[0]:\n",
        "            first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
        "            second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
        "            # first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
        "            # second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
        "            labels = np.array(elem[1], dtype='int32')\n",
        "            X = [first_elem, second_elem]\n",
        "            Y = labels\n",
        "            loss += model.train_on_batch(X, Y)\n",
        "    print('Epoch: ', epoch+1, 'Loss: ', loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25WlTjvDWbkI",
        "outputId": "94b4b454-71ed-4640-d844-1ca0d5d24337"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1 Loss:  345.18286603689194\n",
            "Epoch:  2 Loss:  334.79369938373566\n",
            "Epoch:  3 Loss:  308.41723173856735\n",
            "Epoch:  4 Loss:  260.68071299791336\n",
            "Epoch:  5 Loss:  202.14269189536572\n",
            "Epoch:  6 Loss:  146.9186950325966\n",
            "Epoch:  7 Loss:  102.48286475986242\n",
            "Epoch:  8 Loss:  70.11125607416034\n",
            "Epoch:  9 Loss:  47.86330188438296\n",
            "Epoch:  10 Loss:  32.95165177807212\n",
            "Epoch:  11 Loss:  22.979411309584975\n",
            "Epoch:  12 Loss:  16.24430738016963\n",
            "Epoch:  13 Loss:  11.629797230940312\n",
            "Epoch:  14 Loss:  8.421299951383844\n",
            "Epoch:  15 Loss:  6.160351684316993\n",
            "Epoch:  16 Loss:  4.548642620909959\n",
            "Epoch:  17 Loss:  3.3899174239486456\n",
            "Epoch:  18 Loss:  2.5486590452492237\n",
            "Epoch:  19 Loss:  1.9313176575815305\n",
            "Epoch:  20 Loss:  1.4777417610166594\n",
            "Epoch:  21 Loss:  1.1425434833799955\n",
            "Epoch:  22 Loss:  0.8943536909064278\n",
            "Epoch:  23 Loss:  0.7094871142471675\n",
            "Epoch:  24 Loss:  0.5698129861848429\n",
            "Epoch:  25 Loss:  0.4672195416933391\n",
            "Epoch:  26 Loss:  0.38639783910184633\n",
            "Epoch:  27 Loss:  0.3262074086815119\n",
            "Epoch:  28 Loss:  0.28111608658218756\n",
            "Epoch:  29 Loss:  0.2469056462869048\n",
            "Epoch:  30 Loss:  0.22083746931457426\n",
            "Epoch:  31 Loss:  0.20066161805880256\n",
            "Epoch:  32 Loss:  0.1851212173787644\n",
            "Epoch:  33 Loss:  0.17316485787978309\n",
            "Epoch:  34 Loss:  0.16403788805018849\n",
            "Epoch:  35 Loss:  0.15696750643019186\n",
            "Epoch:  36 Loss:  0.15147515667013067\n",
            "Epoch:  37 Loss:  0.14713097659159757\n",
            "Epoch:  38 Loss:  0.14374383112999567\n",
            "Epoch:  39 Loss:  0.14100896059062507\n",
            "Epoch:  40 Loss:  0.13889059060693398\n",
            "Epoch:  41 Loss:  0.13715485154375529\n",
            "Epoch:  42 Loss:  0.13577229768281995\n",
            "Epoch:  43 Loss:  0.13463179919847335\n",
            "Epoch:  44 Loss:  0.13369764252615823\n",
            "Epoch:  45 Loss:  0.13292676468410036\n",
            "Epoch:  46 Loss:  0.13225670236607812\n",
            "Epoch:  47 Loss:  0.1317007898862812\n",
            "Epoch:  48 Loss:  0.131223780070286\n",
            "Epoch:  49 Loss:  0.13080362692173253\n",
            "Epoch:  50 Loss:  0.13044654132065148\n",
            "Epoch:  51 Loss:  0.13012248655911662\n",
            "Epoch:  52 Loss:  0.12980455779157296\n",
            "Epoch:  53 Loss:  0.12953639012434337\n",
            "Epoch:  54 Loss:  0.12930623831013577\n",
            "Epoch:  55 Loss:  0.12906877267582217\n",
            "Epoch:  56 Loss:  0.12887538525427544\n",
            "Epoch:  57 Loss:  0.12866395703629507\n",
            "Epoch:  58 Loss:  0.12847580230928202\n",
            "Epoch:  59 Loss:  0.12830783072926977\n",
            "Epoch:  60 Loss:  0.12813304844473805\n",
            "Epoch:  61 Loss:  0.12797861585642067\n",
            "Epoch:  62 Loss:  0.12785358087505472\n",
            "Epoch:  63 Loss:  0.12767768998588735\n",
            "Epoch:  64 Loss:  0.12752648246312503\n",
            "Epoch:  65 Loss:  0.12739369306631687\n",
            "Epoch:  66 Loss:  0.12724962007730767\n",
            "Epoch:  67 Loss:  0.1271348066931921\n",
            "Epoch:  68 Loss:  0.12698930743314918\n",
            "Epoch:  69 Loss:  0.1268526405368462\n",
            "Epoch:  70 Loss:  0.1267250467885006\n",
            "Epoch:  71 Loss:  0.1266064663272033\n",
            "Epoch:  72 Loss:  0.12649988267284584\n",
            "Epoch:  73 Loss:  0.1263673861094432\n",
            "Epoch:  74 Loss:  0.12624213234335002\n",
            "Epoch:  75 Loss:  0.12613639695721446\n",
            "Epoch:  76 Loss:  0.12603360301119437\n",
            "Epoch:  77 Loss:  0.12594457734802944\n",
            "Epoch:  78 Loss:  0.12580581839370097\n",
            "Epoch:  79 Loss:  0.12571127848338648\n",
            "Epoch:  80 Loss:  0.12559716263033494\n",
            "Epoch:  81 Loss:  0.12550007877401015\n",
            "Epoch:  82 Loss:  0.12540051605767388\n",
            "Epoch:  83 Loss:  0.12530240534368176\n",
            "Epoch:  84 Loss:  0.12520853094729034\n",
            "Epoch:  85 Loss:  0.1251162760857234\n",
            "Epoch:  86 Loss:  0.12501898539206024\n",
            "Epoch:  87 Loss:  0.124922520419112\n",
            "Epoch:  88 Loss:  0.12482887781341745\n",
            "Epoch:  89 Loss:  0.12474530126040051\n",
            "Epoch:  90 Loss:  0.12465331315749495\n",
            "Epoch:  91 Loss:  0.124560342045271\n",
            "Epoch:  92 Loss:  0.12447354417419376\n",
            "Epoch:  93 Loss:  0.12439182339826615\n",
            "Epoch:  94 Loss:  0.12430687923672323\n",
            "Epoch:  95 Loss:  0.12421539850220498\n",
            "Epoch:  96 Loss:  0.12411569760714514\n",
            "Epoch:  97 Loss:  0.1240187908005339\n",
            "Epoch:  98 Loss:  0.12394307281778794\n",
            "Epoch:  99 Loss:  0.12386168399367392\n",
            "Epoch:  100 Loss:  0.12377275625335571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n"
      ],
      "metadata": {
        "id": "bGREoKHrWuNY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('vectors.txt', 'w')\n",
        "f.write('{} {}\\n'.format(vocab_size, embedding_dim))\n",
        "vectors = model.get_weights()[0]\n",
        "\n",
        "print(vectors)\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    f.write('{} {}\\n'.format(word, ' '.join(map(str, list(vectors[i-1, :])))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEYmhfekhTz2",
        "outputId": "a31d5262-2c69-4af7-b8ce-048c42cfcb97"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-3.6600698e-02  3.1070184e-02 -3.6861908e-02 ... -3.1304561e-02\n",
            "  -4.1251697e-02 -1.3444938e-02]\n",
            " [ 3.4184051e-01 -1.0438968e+00  6.5281022e-01 ...  6.8400669e-01\n",
            "   1.3541592e+00 -1.9816297e-01]\n",
            " [ 9.2822200e-01  9.0662009e-01  1.0685352e+00 ...  9.9791902e-01\n",
            "   4.6768194e-01  5.9400713e-01]\n",
            " ...\n",
            " [ 7.1386695e-03  2.8524626e-02 -4.7016729e-02 ...  1.0430168e-02\n",
            "   2.8662633e-02  3.2484028e-02]\n",
            " [-3.0914461e-02 -3.4251727e-02 -6.8480894e-04 ...  3.1310964e-02\n",
            "   4.7400955e-02 -2.4775757e-02]\n",
            " [ 4.8202228e-02 -4.3179035e-02  1.0251023e-02 ...  9.2054494e-03\n",
            "   2.6368983e-03 -1.8279351e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v = gensim.models.KeyedVectors.load_word2vec_format('./vectors.txt', binary=False)"
      ],
      "metadata": {
        "id": "rZi3XAhMhMa6"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v.most_similar(positive=['악어'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGmgQKkHhQvG",
        "outputId": "ed98e209-2213-4c1b-d350-88f8e2f192cc"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('자신감', 0.3837690055370331),\n",
              " ('시사회', 0.3658345639705658),\n",
              " ('반경', 0.3591010272502899),\n",
              " ('인문학', 0.35634472966194153),\n",
              " ('판옥선', 0.3537239730358124),\n",
              " ('갈림', 0.3450950086116791),\n",
              " ('프렌차이즈', 0.3426169753074646),\n",
              " ('교회', 0.3408311605453491),\n",
              " ('연기', 0.33708080649375916),\n",
              " ('무궁무진', 0.33647608757019043)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v.most_similar(positive=['눈물'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb57efcGiFc0",
        "outputId": "9253de29-113d-4e83-8759-1e31a03094d2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('형님', 0.3972524404525757),\n",
              " ('광장시장', 0.38109156489372253),\n",
              " ('녹화', 0.34661513566970825),\n",
              " ('로간', 0.34656664729118347),\n",
              " ('배색', 0.3448937237262726),\n",
              " ('앱', 0.33743584156036377),\n",
              " ('빠오님', 0.3320561647415161),\n",
              " ('늘어트렸', 0.3315449357032776),\n",
              " ('카페라떼', 0.3310122787952423),\n",
              " ('이따', 0.32716938853263855)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5DXhamt7iKIB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}